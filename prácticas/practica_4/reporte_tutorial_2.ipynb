{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reporte_tutorial_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlIMqxjjsr+tPEuz4BV3dw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9aK-S6MC8wra"},"outputs":[],"source":["# baseline model performance on the wine dataset\n","from numpy import mean\n","from numpy import std\n","from pandas import read_csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","# load the dataset\n","url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n","df = read_csv(url, header=None)\n","data = df.values\n","X, y = data[:, :-1], data[:, -1]\n","# minimally prepare dataset\n","X = X.astype('float')\n","y = LabelEncoder().fit_transform(y.astype('str'))\n","# define the model\n","model = LogisticRegression(solver='liblinear')\n","# define the cross-validation procedure\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","# evaluate model\n","scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n","# report performance\n","print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"]},{"cell_type":"code","source":["# data preparation as feature engineering for wine dataset\n","from numpy import mean\n","from numpy import std\n","from pandas import read_csv\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import QuantileTransformer\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.decomposition import PCA\n","from sklearn.decomposition import TruncatedSVD\n","# load the dataset\n","url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n","df = read_csv(url, header=None)\n","data = df.values\n","X, y = data[:, :-1], data[:, -1]\n","# minimally prepare dataset\n","X = X.astype('float')\n","y = LabelEncoder().fit_transform(y.astype('str'))\n","# transforms for the feature union\n","transforms = list()\n","transforms.append(('mms', MinMaxScaler()))\n","transforms.append(('ss', StandardScaler()))\n","transforms.append(('rs', RobustScaler()))\n","transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n","transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n","transforms.append(('pca', PCA(n_components=7)))\n","transforms.append(('svd', TruncatedSVD(n_components=7)))\n","# create the feature union\n","fu = FeatureUnion(transforms)\n","# define the model\n","model = LogisticRegression(solver='liblinear')\n","# define the pipeline\n","steps = list()\n","steps.append(('fu', fu))\n","steps.append(('m', model))\n","pipeline = Pipeline(steps=steps)\n","# define the cross-validation procedure\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","# evaluate model\n","scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n","# report performance\n","print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"],"metadata":{"id":"cv2XuuQ1xCnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data preparation as feature engineering with feature selection for wine dataset\n","from numpy import mean\n","from numpy import std\n","from pandas import read_csv\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import QuantileTransformer\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.feature_selection import RFE\n","from sklearn.decomposition import PCA\n","from sklearn.decomposition import TruncatedSVD\n","# load the dataset\n","url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n","df = read_csv(url, header=None)\n","data = df.values\n","X, y = data[:, :-1], data[:, -1]\n","# minimally prepare dataset\n","X = X.astype('float')\n","y = LabelEncoder().fit_transform(y.astype('str'))\n","# transforms for the feature union\n","transforms = list()\n","transforms.append(('mms', MinMaxScaler()))\n","transforms.append(('ss', StandardScaler()))\n","transforms.append(('rs', RobustScaler()))\n","transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n","transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n","transforms.append(('pca', PCA(n_components=7)))\n","transforms.append(('svd', TruncatedSVD(n_components=7)))\n","# create the feature union\n","fu = FeatureUnion(transforms)\n","# define the feature selection\n","rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=15)\n","# define the model\n","model = LogisticRegression(solver='liblinear')\n","# define the pipeline\n","steps = list()\n","steps.append(('fu', fu))\n","steps.append(('rfe', rfe))\n","steps.append(('m', model))\n","pipeline = Pipeline(steps=steps)\n","# define the cross-validation procedure\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","# evaluate model\n","scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n","# report performance\n","print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"],"metadata":{"id":"3h5cAFVoxOjd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Comentarios del ejercicio**"],"metadata":{"id":"Q_PGlNq20-Wf"}},{"cell_type":"markdown","source":["Existen muchas cosas que se pueden hacer sobre un dataset antes de comenzar a utilizarlo con un modelo predictivo. Se pueden preparar los datos utilizando distintas técnicas, que combinadas en un solo dataset, producen un conjunto de datos mejor preparado para ser entrenado y probado por un modelo predictivo, tal como lo hacen en el blog. Dependiendo de las técnicas utilizadas, el rendimiento puede ir mejorando o empeorando, pero como sucede usualmente en este campo, se debe experimentar para ver cuál combinación es la que da mejores resultados. En un futuro y en próximas investigaciones espero aplicar mejor las técnicas de preparación de un dataset antes de ser utilizado."],"metadata":{"id":"8E-VxWUw1Akt"}}]}