{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reporte_tutorial_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPJLs3JyFO/nLf1sGQyn86w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Ya tenía conocimiento del proceso de *feature selection* gracias a un curso anterior. Conocía de que existían métodos supervisados y no supervisados pero no conocía la diferencia entre uno y otro, que es el uso o no de la variable de respuesta. También sobre las distintas técnicas estadísticas para un *feature selection* basado en filtros, que dependiendo del tipo de variables de entrada y de variable de salida, se puede elegir una u otra técnica (anova, chi-cuadrado, etc.), por lo que es importante conocer la naturaleza de las variables del dataset, si están más definidas, es mejor."],"metadata":{"id":"ePlYMCHB64sc"}},{"cell_type":"markdown","source":["El proceso de *feature selection* es muy importante para que un modelo predictivo pueda tener un buen rendimiento, aunque parece que también es un proceso muy de prueba-error, espero que en futuras investigaciones me sirva para agilizar las fases antes de construir y entrenar un modelo."],"metadata":{"id":"Isg2oaUj8UwA"}}]}